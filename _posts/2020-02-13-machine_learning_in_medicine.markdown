---
layout: post
title:      "Machine Learning in Medicine"
date:       2020-02-13 06:46:17 +0000
permalink:  machine_learning_in_medicine
---


Allow me to introduce my latest project! For this one, we were tasked with finding our own dataset and asking a question that we could solve using classification. At first, this was intimidating. There’s so many datasets, and even more questions that could be answered with them. As a pharmacy technician, naturally, I think about medications… a lot. This really guided my search as I set out to find a dataset. I chose to do a data-first approach; find the data first, and the question second. On Kaggle, I found the 2013-2014 NHANES (National Health And Nutrition Examination Study) study. This thing is a gold mine. As I explored the data, I formulated a question- what if I could use machine learning and participant answers to dietary questions to predict if they take insulin? Because I know you’re curious, I’ll go over my methodology and conclusions, but what I would really like to discuss is the use of machine learning in medicine. We’ll end on some ideas for future work and how to improve. I hope you enjoy this project as much as I did. 

**Brief overview of methodology**
I began with copious data cleaning. My first task was to encode whether a participant took insulin or not. I did this by creating a function that would assign a binary value to each participant ID number. 1 if they took insulin, 0 if they did not. I combined this with the diet dataframe and replaced all null values with zero. This gave me one dataframe that contained my target variable (insulin) and my dietary features. 
In the interest of trying multiple models, I decided to use a Random Forest Classifier, K Nearest Neighbors, and XGBoost. Because my dataset was incredibly unbalanced, I decided to use F1 score to measure model performance rather than accuracy score. My best performing model was XGBoost with an F1 score of 0.06. After using GridSearchCV to tune the hyperparameters, that F1 increased 4.9% to 0.11. 
It is well known that sugar consumption affects blood glucose, so next I ran my model again, this time removing features like sugar consumption and questions regarding special diets. This model, even after being tuned, didn’t correctly predict anybody on insulin. I was disappointed at first, but I realized that no result is still a result. 
Lastly, I repeated the process with a drug called Glipizide. Both Type 1 and Type 2 diabetics take insulin, so I wanted to see if my results would change with a medication that only treats Type 2 diabetes. I found for this one that KNN was actually my best model with an F1 score of 0.04. 

**Conclusions drawn**
Using the Random Forest Classifier, I was able to list the most important features in predicting insulin prescriptions. The top three were: special diets, sugar consumption, and caffeine consumption. This was interesting to me, so I looked into how the diets were input. I found that there were only two values in the column- null values, and those who refused to answer. My assumption is that caffeine was an indicator not because of caffeine itself, but rather sugary sodas, coffees and energy drinks. 
It is interesting to note that these models predicted people to be on insulin when they actually weren’t. I believe that this could be a signal to a participant that they may need to talk to their doctor about their diet- if they have common factors with those that are on insulin, they may be at risk of needing it in the future. 
Trying to remove the ‘cheat’ features (sugar consumption) did not yield very impressive results. However, that just goes to reinforce the importance of watching sugar consumption as it relates to the development of Type 2 diabetes. 
I’m hesitant to make recommendations based on the Glipizide model, simply because the data was even more unbalanced than the insulin data. There were 25 participants who were predicted to have Glipizide prescriptions that actually didn’t. They may benefit from dietary changes, but it could also be error on the algorithm’s part. 

**Discussion of advantages and disadvantages to using machine learning in medicine**
This kind of research could be extremely beneficial to the medical community. Machine learning has the potential to use data that already exists to improve the lives of patients. In the case of this project in particular, it could be cheaper and more efficient to identify patients who are at risk of developing Type 2 diabetes before they have an adverse health event. Another benefit of machine learning is that it can bring awareness to factors that aren’t traditionally thought of. We know that consuming a lot of sugar is hazardous to someone’s health. But maybe there is a link between Glipizide prescriptions and a dietary factor that hasn’t been thought of and warrants further research. 
That being said, there are potentially real drawbacks to using machine learning in medicine. A computer can’t treat the whole patient. This was a problem in this dataset. For example, participants may have recently adjusted their diet in response to an insulin prescription. We also can’t guarantee that data is accurate, especially when it comes to humans. People may be hesitant to truthfully answer questions, especially about sensitive subjects like weight loss diets, alcohol consumption, or even amount of insulin that diabetics take.  Another drawback is that making meaningful conclusions requires a large amount of data. Patients may not be willing to consent to sharing their medical information, so those that do may not create a representative dataset. 
Even with the disadvantages, I personally believe machine learning definitely has a place in healthcare. It may take time and a balance between using a computer and using a real person, but the insights gained from using machine learning have potential to help patients even before they are sick. 

**How to improve, future work**
There were some areas that I feel could definitely be improved on in this project. First and foremost, the unbalanced data should be adjusted. I would use SMOTE and see if that improves our models at all. This would be especially important if another drug was studied, like in the case of the Glipizide. 
With the Glipizide model, I would be curious to see if there is a way to look at the feature importances. I used a K Nearest Neighbor model which meant it wasn’t possible on that model, but it would be worth looking into if the risk factors for Glipizide prescriptions yield any interesting results. 
Lastly, there are a lot of ways that you could go about answering this question. There were dataframes that contained blood insulin levels and diagnosis codes. It might be worth looking at if the results would change based on different target variables. This could even be used in addition to the information we found here. 

It was hard to know where to stop on this project. There was such a wealth of information to use. It was so interesting to see how machine learning can potentially be used to improve patient outcomes.  Especially in the instances we found here where a false insulin prediction could lead to a conversation between patient and doctor, I believe that using data such as the NHANES could definitely benefit the medical community. This was an exciting project, and I’m definitely pleased with the results.
