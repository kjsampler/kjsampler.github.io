---
layout: post
title:      "AI In Health Care"
date:       2021-05-10 04:18:07 +0000
permalink:  ai_in_health_care
---


So tonight's post is another article that I want to summarize and share with you all. It is [Hard Choices: AI in Health Care](http://https://medicine.yale.edu/news/yale-medicine-magazine/hard-choices-ai-in-health-care/), featured in the Data Science Weekly newsletter. Because of my background in health care, and my passion for data science, of course this article caught my eye! Without further ado, let's jump in.  

The article focuses on two main concerns: the loss of doctor autonomy and the potential for biased results. While I am a proponent of what I have seen of AI in health care (granted, not much), the question of doctor autonomy was one that I hadn't considered. The concern is that with AI making "decisions" regarding medical care, it would be up to the doctor to oversee the care, and potentially disagree with the AI. I personally believe that a doctor is well within their rights to do that, but this article is discussing future problems that could arise. And the author is correct to point out that in a society as litigious as the US, it would raise a lot of ethical questions if a patient had a bad outcome after a physician disagreed with the AI. The goal is that AI would aid a doctor's decision, never hinder it, but it's so important to consider the possibilities in a field that is so rapidly expanding.  

The other concern they focus on is the bias found in AI. Granted, humans tend to be biased in general, but it is easier to educate a person on their bias than it is to undo the training that made an AI biased. I am thinking of an algorithm that came out last year that would take a blurry image and produce a clear version of the image. The problem is that the algorithm had not been trained on a relatively non-diverse dataset, and therefore was more likely to produce a clear image of a Caucasian man even when the input was not a Caucasian man. In the case of an image, this was caught very quickly. However, there are so many scenarios in medicine where bias could lead to delays in care and potential misdiagnoses. And again, when a doctor knows better than the AI, they will be faced with the daunting task of saying that they know better. It's not an enviable position.  

I found this article very enjoyable. It brought up some points that I had not fully considered, because I tend to think of healthcare AI as a positive thing. At its best, it's a tool. It can make healthcare more person based, efficient, and in many cases cheaper. But there is the potential for things to go wrong, and for the negatives to start showing up. In an exploding field, it's important to think of these negatives before they go into production. That's all I've got for you this week guys, but thanks so much for reading through! Until next week!
