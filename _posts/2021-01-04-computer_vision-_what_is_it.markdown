---
layout: post
title:      "Computer Vision- What is It? "
date:       2021-01-04 05:49:19 +0000
permalink:  computer_vision-_what_is_it
---

I’ve been spending a lot of time on LinkedIn lately. And something that I’ve noticed coming up in job postings, blogs and skills within my network is Computer Vision. To keep seeing it and not know what it is felt like a sign from the universe, so I started researching. This is what I’ve gathered so far- and keep in mind this is going to be very high level and my general impressions for now. Please feel free to reach out and correct me, answer questions, and continue any discussions via LinkedIn or email!  
The first thing that interested me was that Computer Vision is just how it sounds- it is the science of how computers “see”. Or specifically, how they can process the photographic evidence to make decisions, just like we do as humans. I found it coincidental that this should grab my interest when a similar subject came up in my personal reading. In Pilgrim at Tinker Creek by Annie Dillard, she spends time in the chapter “Seeing” talking about a book that *she* read, in which previously blind patients try to describe what it is like to learn to see. The discussion is awesome and I would recommend Dillard to anyone who is curious. But it definitely grabbed my attention to read about people learning to see, and start researching how computers are learning to see.  
Something that came up a lot in my research was that a huge problem in Computer Vision is that, well, we don’t even have a full grasp on how we as humans see. So even something as “simple” as seeing a book, knowing it’s a book, and making a decision based on that evidence is actually unknowingly complex. It has been the goal of scientists since the 1950’s to imitate something that humans do without even realizing. Another problem that may get skipped over is that computers do better with contained datasets and clear pictures. It becomes almost impossible to account for the anomalies that we deal with as humans- things like changing light, angles or occlusions (that is, objects in the way of what we’re actually looking at, like foggy glasses.) Of course, teaching a computer to see is a huge undertaking and these are not the only problems (far from it) but they were two that I saw over and over again in my research.  
Learning about the blockers, I kept wondering to myself- how has science gotten around these. After all, I have a program on my tablet that recognizes TV shows via the camera, Apple products have facial recognition, and self driving cars are getting a lot of attention lately. All of these are things that I would intuit need sight, and the ability to make decisions (identify a show, unlock a phone, make a left turn). So Computer Vision is out there. I learned that the programming itself is not reinventing the wheel. TensorFlow, PyTorch and AWS- things I’ve already been exposed to- are already common players in the game. The real secret sauce lies in having huge training sets that make these algorithms incredibly smart, and good at what they do. We definitely can’t take for granted that running powerful algorithms on enormous sets of data takes a lot of computing power, which was not always readily available in the past. We’re living in a time that processing big data is not always easy, but it is attainable.  
One of the areas of Computer Vision that I found most interesting was, of course, in medicine. Computer Vision is affording healthcare workers an extra set of eyes. Changes in size in the human body that may be undetectable to the human eye could be rather obvious to a computer. And when you’re working with something small, like examining arteries for atherosclerosis, that can be indispensable. Something that also intrigued me that I didn’t read much about was the possibilities that Computer Vision opens up in the art world. I think first of identification- perhaps an algorithm could take in a video of a ballerina, identify the specific dances, and link a student to a tutorial of said dance. There is a lot going on in the world of photography and Computer Vision, specifically with cameras that will follow a face, an actor, or whatever you want to program it to do. The possibilities are just starting.  
So, from my previous knowledge, I know that when a computer is “looking” at an image, it is actually looking at a matrix of values that we know as RGB. Where I would ask for feedback, discussion, or further reading is the question of how a computer watches a video. The concept of Computer Vision, to me, seems that the algorithm has to do more than one step- it has to respond to whatever it is seeing, meaning the image is dynamic. I would love advice on where to learn more about that!  
Like I said, this is a pretty high level overview of what I’ve been learning. I have found myself in the deep end of the pool trying to understand Computer Vision, but I think that summarizing is always a good place to check in with new learning. I welcome any feedback on LinkedIn or via email. I hope you’ve enjoyed this post, and I look forward to sharing with you what else is new in the coming weeks!The content of your blog post goes here.
